{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2dcc3-e553-4b0b-ad7a-88d2834ba7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "file_name = r\"C:\\Users\\LENOVO\\Desktop\\prediction\\Data\\Maintext_cleaned.txt\"\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        text = file.read().strip()\n",
    "    if not text:\n",
    "        raise ValueError(\"Error: فایل متنی خالی است یا محتوای مناسبی ندارد.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File {file_name} not found.\")\n",
    "    text = \"\"\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    text = \"\"\n",
    "\n",
    "if text:\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts([text])\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "    input_sequences = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "            for i in range(1, len(token_list)):\n",
    "                input_sequences.append(token_list[:i + 1])\n",
    "\n",
    "    if not input_sequences:\n",
    "        raise ValueError(\"Error: هیچ توالی‌ای تولید نشد. فایل ممکن است نامعتبر باشد.\")\n",
    "\n",
    "    \n",
    "    max_sequence_len = max(len(seq) for seq in input_sequences)\n",
    "    input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "    \n",
    "    X = input_sequences[:, :-1]\n",
    "    y = input_sequences[:, -1]\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "    \n",
    "    embedding_dim = 100\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=total_words, output_dim=embedding_dim),\n",
    "        LSTM(150, return_sequences=True),\n",
    "        LSTM(100),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    num_epochs = 50\n",
    "    history = model.fit(X, y, epochs=num_epochs, verbose=1)\n",
    "\n",
    "    \n",
    "    def generate_text(seed_text, next_words, max_sequence_len):\n",
    "        for _ in range(next_words):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
    "            predicted_index = np.argmax(model.predict(token_list, verbose=0))\n",
    "            output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
    "            seed_text += \" \" + output_word\n",
    "        return seed_text\n",
    "\n",
    "    \n",
    "    seed_text = \"اکنون بسوی شما مراجعت خواهم کرد\"\n",
    "    next_words = 5\n",
    "    generated_text = generate_text(seed_text, next_words, max_sequence_len)\n",
    "    print(generated_text)\n",
    "else:\n",
    "    print(\"برنامه به پایان رسید. متن مناسبی برای پردازش یافت نشد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b765d6-6e81-417b-b9ec-90269d038072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
